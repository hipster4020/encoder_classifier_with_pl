{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:30:06.009678Z",
     "start_time": "2022-02-28T01:30:05.562643Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:30:16.285210Z",
     "start_time": "2022-02-28T01:30:16.277126Z"
    },
    "id": "ahc_PV2F4WxX"
   },
   "outputs": [],
   "source": [
    "def dump_jsonl(data, output_path, append=False):\n",
    "    mode = \"a+\" if append else \"w\"\n",
    "    with open(output_path, mode, encoding=\"utf-8\") as f:\n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False)\n",
    "            f.write(json_record + \"\\n\")\n",
    "\n",
    "\n",
    "def load_jsonl(input_path) -> list:\n",
    "    data = []\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip(\"\\n|\\r\")))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:30:17.580307Z",
     "start_time": "2022-02-28T01:30:17.576489Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 24000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoCW3M3_HeeV"
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:30:18.874123Z",
     "start_time": "2022-02-28T01:30:18.868413Z"
    }
   },
   "outputs": [],
   "source": [
    "def processing(text):\n",
    "    text = re.sub(r' +', r' ', text.strip())\n",
    "    text = re.sub(r'(.{8,}?)\\1+', r'\\1', text)\n",
    "    text = re.sub(r'[^ ㄱ-ㅎㅏ-ㅣ가-힣A-Za-z0-9~!@#$%\\^\\&*\\(\\)_\\+\\-=\\[\\]{},\\./<>\\?]', r'', text)\n",
    "    text = re.sub(r'http.+', r'[URL]', text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:31:05.599350Z",
     "start_time": "2022-02-28T01:30:20.504397Z"
    }
   },
   "outputs": [],
   "source": [
    "data = load_jsonl('category.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:31:05.631566Z",
     "start_time": "2022-02-28T01:31:05.627346Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen():\n",
    "    for row in data:\n",
    "        yield processing(row['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:31:16.185253Z",
     "start_time": "2022-02-28T01:31:16.164451Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]',\n",
      " '[UNK]',\n",
      " '[CLS]',\n",
      " '[SEP]',\n",
      " '[MASK]',\n",
      " '[BOS]',\n",
      " '[EOS]',\n",
      " '[TSEP]',\n",
      " '[NAME]',\n",
      " '[URL]',\n",
      " '[UNK0]',\n",
      " '[UNK1]',\n",
      " '[UNK2]',\n",
      " '[UNK3]',\n",
      " '[UNK4]',\n",
      " '[UNK5]',\n",
      " '[UNK6]',\n",
      " '[UNK7]',\n",
      " '[UNK8]',\n",
      " '[UNK9]',\n",
      " '[UNUSED0]',\n",
      " '[UNUSED1]',\n",
      " '[UNUSED2]',\n",
      " '[UNUSED3]',\n",
      " '[UNUSED4]',\n",
      " '[UNUSED5]',\n",
      " '[UNUSED6]',\n",
      " '[UNUSED7]',\n",
      " '[UNUSED8]',\n",
      " '[UNUSED9]',\n",
      " '[UNUSED10]',\n",
      " '[UNUSED11]',\n",
      " '[UNUSED12]',\n",
      " '[UNUSED13]',\n",
      " '[UNUSED14]',\n",
      " '[UNUSED15]',\n",
      " '[UNUSED16]',\n",
      " '[UNUSED17]',\n",
      " '[UNUSED18]',\n",
      " '[UNUSED19]',\n",
      " '[UNUSED20]',\n",
      " '[UNUSED21]',\n",
      " '[UNUSED22]',\n",
      " '[UNUSED23]',\n",
      " '[UNUSED24]',\n",
      " '[UNUSED25]',\n",
      " '[UNUSED26]',\n",
      " '[UNUSED27]',\n",
      " '[UNUSED28]',\n",
      " '[UNUSED29]',\n",
      " '[UNUSED30]',\n",
      " '[UNUSED31]',\n",
      " '[UNUSED32]',\n",
      " '[UNUSED33]',\n",
      " '[UNUSED34]',\n",
      " '[UNUSED35]',\n",
      " '[UNUSED36]',\n",
      " '[UNUSED37]',\n",
      " '[UNUSED38]',\n",
      " '[UNUSED39]',\n",
      " '[UNUSED40]',\n",
      " '[UNUSED41]',\n",
      " '[UNUSED42]',\n",
      " '[UNUSED43]',\n",
      " '[UNUSED44]',\n",
      " '[UNUSED45]',\n",
      " '[UNUSED46]',\n",
      " '[UNUSED47]',\n",
      " '[UNUSED48]',\n",
      " '[UNUSED49]',\n",
      " '[UNUSED50]',\n",
      " '[UNUSED51]',\n",
      " '[UNUSED52]',\n",
      " '[UNUSED53]',\n",
      " '[UNUSED54]',\n",
      " '[UNUSED55]',\n",
      " '[UNUSED56]',\n",
      " '[UNUSED57]',\n",
      " '[UNUSED58]',\n",
      " '[UNUSED59]',\n",
      " '[UNUSED60]',\n",
      " '[UNUSED61]',\n",
      " '[UNUSED62]',\n",
      " '[UNUSED63]',\n",
      " '[UNUSED64]',\n",
      " '[UNUSED65]',\n",
      " '[UNUSED66]',\n",
      " '[UNUSED67]',\n",
      " '[UNUSED68]',\n",
      " '[UNUSED69]',\n",
      " '[UNUSED70]',\n",
      " '[UNUSED71]',\n",
      " '[UNUSED72]',\n",
      " '[UNUSED73]',\n",
      " '[UNUSED74]',\n",
      " '[UNUSED75]',\n",
      " '[UNUSED76]',\n",
      " '[UNUSED77]',\n",
      " '[UNUSED78]',\n",
      " '[UNUSED79]',\n",
      " '[UNUSED80]',\n",
      " '[UNUSED81]',\n",
      " '[UNUSED82]',\n",
      " '[UNUSED83]',\n",
      " '[UNUSED84]',\n",
      " '[UNUSED85]',\n",
      " '[UNUSED86]',\n",
      " '[UNUSED87]',\n",
      " '[UNUSED88]',\n",
      " '[UNUSED89]',\n",
      " '[UNUSED90]',\n",
      " '[UNUSED91]',\n",
      " '[UNUSED92]',\n",
      " '[UNUSED93]',\n",
      " '[UNUSED94]',\n",
      " '[UNUSED95]',\n",
      " '[UNUSED96]',\n",
      " '[UNUSED97]',\n",
      " '[UNUSED98]',\n",
      " '[UNUSED99]']\n"
     ]
    }
   ],
   "source": [
    "user_defined_symbols = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"[BOS]\", \"[EOS]\", \"[TSEP]\", \"[NAME]\", \"[URL]\"]\n",
    "user_defined_symbols += [f\"[UNK{i}]\" for i in range(10)]\n",
    "unused_token_num = 100\n",
    "unused_list = [f\"[UNUSED{i}]\" for i in range(100)]\n",
    "user_defined_symbols += unused_list\n",
    "\n",
    "pprint(user_defined_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M78kc0QyHjW6"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:31:27.226189Z",
     "start_time": "2022-02-28T01:31:27.213352Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "\n",
    "bert_tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:31:38.583566Z",
     "start_time": "2022-02-28T01:31:38.578697Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import Lowercase, NFD, StripAccents\n",
    "\n",
    "bert_tokenizer.normalizer = normalizers.Sequence([NFD(), Lowercase(), StripAccents()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:31:39.951116Z",
     "start_time": "2022-02-28T01:31:39.947288Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "bert_tokenizer.pre_tokenizer = Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:31:41.273368Z",
     "start_time": "2022-02-28T01:31:41.268391Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "bert_tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[(t, i) for i, t in enumerate(user_defined_symbols)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:44:00.048196Z",
     "start_time": "2022-02-28T01:31:42.250921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers.trainers import WordPieceTrainer\n",
    "\n",
    "trainer = WordPieceTrainer(\n",
    "    vocab_size=vocab_size, \n",
    "    special_tokens=user_defined_symbols,\n",
    ")\n",
    "bert_tokenizer.train_from_iterator(gen(), trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:44:00.056369Z",
     "start_time": "2022-02-28T01:44:00.050181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 8541, 3472, 911, 614, 3972, 1459, 146, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'테스트 ##용이 ##ᆫ데 잘 되는거 ##같아 ?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = bert_tokenizer.encode(\"테스트용인데 잘 되는거같아?\")\n",
    "print(output.ids)\n",
    "\n",
    "bert_tokenizer.decode(output.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:44:00.071199Z",
     "start_time": "2022-02-28T01:44:00.057864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'테스트용인데 잘 되는거같아?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import decoders\n",
    "\n",
    "bert_tokenizer.decoder = decoders.WordPiece()\n",
    "bert_tokenizer.decode(output.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert transformers tokenizer and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:46:03.361839Z",
     "start_time": "2022-02-28T01:46:01.625549Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizerFast\n",
    "\n",
    "\n",
    "fast_tokenizer = ElectraTokenizerFast(tokenizer_object=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:46:03.504487Z",
     "start_time": "2022-02-28T01:46:03.496017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.pad_token = \"[PAD]\"\n",
    "fast_tokenizer.unk_token = \"[UNK]\"\n",
    "fast_tokenizer.cls_token = \"[CLS]\"\n",
    "fast_tokenizer.sep_token = \"[SEP]\"\n",
    "fast_tokenizer.mask_token = \"[MASK]\"\n",
    "fast_tokenizer.bos_token = \"[BOS]\"\n",
    "fast_tokenizer.eos_token = \"[EOS]\"\n",
    "\n",
    "special_tokens_dict = {'additional_special_tokens': user_defined_symbols}\n",
    "fast_tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:46:06.966327Z",
     "start_time": "2022-02-28T01:46:05.117266Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 10:46:05.244813: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 테스트용 [SEP]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.decode(fast_tokenizer.encode(\"테스트용\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:46:09.039000Z",
     "start_time": "2022-02-28T01:46:08.977106Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('etc/DialogWordPiece/tokenizer_config.json',\n",
       " 'etc/DialogWordPiece/special_tokens_map.json',\n",
       " 'etc/DialogWordPiece/vocab.txt',\n",
       " 'etc/DialogWordPiece/added_tokens.json',\n",
       " 'etc/DialogWordPiece/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.save_pretrained(\"tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HoCW3M3_HeeV",
    "M78kc0QyHjW6",
    "ETFAiEUiHgrG"
   ],
   "name": "evolved_transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
